action: ??? # train or test
name: ??? # name of the experiment needed for the logs
modality: ??? #["RGB"] #["RGB", "EMG"] 
total_batch: 32 #128 # total batch size if training is done with gradient accumulation
batch_size: 32 # batch size for the forward
gpus: null # gpus adopted
wandb_name: null # needed for wandb logging
resume_from: null # checkpoint directory
logname: null # name of the logs
models_dir: null # directory containing all the models
feat_avg: ??? #if true it computes the average of the features and feed to MLP. If False, 1 logit s compute for each clip for the same record, and logits are then averaged

# training parameters
train:
  num_iter: 5000 # number of training iterations with total_batch size
  lr_steps: 5000 # steps before reducing learning rate
  eval_freq: 1000 # evaluation frequency
  num_clips: ??? #5 #10
  dense_sampling: # sampling version adopted in training for each modality
    RGB: ??? #True #False
  num_frames_per_clip: # number of frames adopted in training for each modality
    RGB: ??? #16 #25

test:
  num_clips: ??? # number of clips in testing
  dense_sampling: # sampling version adopted in test for each modality
    RGB: ??? #True #False
  num_frames_per_clip: # number of frames adopted in test for each modality
    RGB: ??? #16 #25

dataset:
  annotations_path: ??? #train_val #Action-Net/data/EMG_datapreprocessed_data 
  shift: ??? #D1-D1 #SXY-SXY
  workers: 4 # number of workers for the dataloader
  stride: 2 # stride in case of dense sampling
  resolution: 224 # input resolution to the model
  RGB:
    features_name: ??? #saved_feat_I3D_5 #saved_feat_I3D_25
    data_path: ???  #Epic-Kitchen_RGB
    tmpl: "img_{:010d}.jpg" # format of RGB filenames
  EMG:
    data_path: ??? 
    tmpl: "array_{:010d}.txt" #JUST placeholder (not used for emg)
    features_name: ???

# these are the action recognition models for each modality
models:
  RGB:
    model: ??? #MLP #LSTM #TRANSFORMER
    normalize: ???
    dropout: ???
    kwargs: {}
    lr_steps: 3000
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7
  EMG:
    model: ??? #MLP_EMG #LSTM_EMG #TRANSFORMER
    normalize: ???
    dropout: ???
    kwargs: {}
    lr_steps: 3000
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7
